{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidpythonseo/davidpythonseo/blob/main/whisper_youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Youtube Videos Transcription with OpenAI's Whisper**\n",
        "\n",
        "[![blog post shield](https://img.shields.io/static/v1?label=&message=Blog%20post&color=blue&style=for-the-badge&logo=openai&link=https://openai.com/blog/whisper)](https://openai.com/blog/whisper)\n",
        "[![notebook shield](https://img.shields.io/static/v1?label=&message=Notebook&color=blue&style=for-the-badge&logo=googlecolab&link=https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)](https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)\n",
        "[![repository shield](https://img.shields.io/static/v1?label=&message=Repository&color=blue&style=for-the-badge&logo=github&link=https://github.com/openai/whisper)](https://github.com/openai/whisper)\n",
        "[![paper shield](https://img.shields.io/static/v1?label=&message=Paper&color=blue&style=for-the-badge&link=https://cdn.openai.com/papers/whisper.pdf)](https://cdn.openai.com/papers/whisper.pdf)\n",
        "[![model card shield](https://img.shields.io/static/v1?label=&message=Model%20card&color=blue&style=for-the-badge&link=https://github.com/openai/whisper/blob/main/model-card.md)](https://github.com/openai/whisper/blob/main/model-card.md)\n",
        "\n",
        "Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\n",
        "\n",
        "This Notebook will guide you through the transcription of a Youtube video using Whisper. You'll be able to explore most inference parameters or use the Notebook as-is to store the transcript and video audio in your Google Drive."
      ],
      "metadata": {
        "id": "96kvih9mXkNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Check GPU type** 🕵️\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime &rarr; Change runtime type &rarr; Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QshUbLqpX7L4",
        "outputId": "339f9b97-52d4-42ed-9254-6ce66200ce7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-d353159e-2f87-24b4-dc02-4b2ecddb3b1b)\n",
            "Thu May  4 23:33:52 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IfG0E_WbRFI0",
        "cellView": "form",
        "outputId": "6145aaf7-3f59-4e48-b949-69ff5dcc04f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-h776ustm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-h776ustm\n",
            "  Resolved https://github.com/openai/whisper.git to commit 55237228425e39828bbb964fd7bf774c9962eb67\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.0+cu118)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Collecting tiktoken==0.3.3\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.12.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (67.7.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230314) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798010 sha256=7f04a297d6494a1bc6178cae1b9977333762efb3b8e10cda186abaa8b0277365\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c9fpr9l0/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20230314 tiktoken-0.3.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2023.3.4-py2.py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2022.12.7)\n",
            "Collecting websockets\n",
            "  Downloading websockets-11.0.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen\n",
            "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex\n",
            "  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: brotli, websockets, pycryptodomex, mutagen, yt-dlp\n",
            "Successfully installed brotli-1.0.9 mutagen-1.46.0 pycryptodomex-3.17 websockets-11.0.2 yt-dlp-2023.3.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Install libraries** 🏗️\n",
        "#@markdown This cell will take a little while to download several libraries, including Whisper.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install yt-dlp\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1zwGAsr4sIgd",
        "cellView": "form",
        "outputId": "f40ad2cb-d654-43ed-aea4-9a5db0d9f6c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Optional:** Save data in Google Drive 💾\n",
        "#@markdown Enter a Google Drive path and run this cell if you want to store the results inside Google Drive.\n",
        "\n",
        "# Uncomment to copy generated images to drive, faster than downloading directly from colab in my experience.\n",
        "from google.colab import drive\n",
        "drive_mount_path = Path(\"/\") / \"content\" / \"drive\"\n",
        "drive.mount(str(drive_mount_path))\n",
        "drive_mount_path /= \"My Drive\"\n",
        "#@markdown ---\n",
        "drive_path = \"Colab Notebooks/Whisper Youtube\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change your Google Drive path.**\n",
        "\n",
        "drive_whisper_path = drive_mount_path / Path(drive_path.lstrip(\"/\"))\n",
        "drive_whisper_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Model selection** 🧠\n",
        "\n",
        "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "#@markdown | large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "Model = 'large' #@param ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large']\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "whisper_model = whisper.load_model(Model)\n",
        "\n",
        "if Model in whisper.available_models():\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is selected.**\"\n",
        "    ))\n",
        "else:\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is no longer available.**<br /> Please select one of the following:<br /> - {'<br /> - '.join(whisper.available_models())}\"\n",
        "    ))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TMhrSq_GZ6kA",
        "outputId": "2e5da4d1-5368-4bea-ba10-91e56c67f931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [00:48<00:00, 63.3MiB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**large model is selected.**"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Video selection** 📺\n",
        "\n",
        "#@markdown Enter the URL of the Youtube video you want to transcribe, wether you want to save the audio file in your Google Drive, and run the cell.\n",
        "\n",
        "Type = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive']\n",
        "#@markdown ---\n",
        "#@markdown #### **Youtube video or playlist**\n",
        "URL = \"https://youtu.be/bwWmI3krjEo\" #@param {type:\"string\"}\n",
        "# store_audio = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### **Google Drive video, audio (mp4, wav), or folder containing video and/or audio files**\n",
        "video_path = \"Colab Notebooks/transcription/my_video.mp4\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "    \n",
        "    ydl_opts = {\n",
        "        'format': 'm4a/bestaudio/best',\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "        # ℹ️ See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "        'postprocessors': [{  # Extract audio using ffmpeg\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        error_code = ydl.download([URL])\n",
        "        list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "        \n",
        "    for video_info in list_video_info:\n",
        "        video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "elif Type == \"Google Drive\":\n",
        "    # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    if video_path.is_dir():\n",
        "        for video_path_drive in video_path.glob(\"**/*\"):\n",
        "            if video_path_drive.is_file():\n",
        "                display(Markdown(f\"**{str(video_path_drive)} selected for transcription.**\"))\n",
        "            elif video_path_drive.is_dir():\n",
        "                display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "            else:\n",
        "                display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "            video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "            shutil.copy(video_path_drive, video_path_local)\n",
        "            video_path_local_list.append(video_path_local)\n",
        "    elif video_path.is_file():\n",
        "        video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "        shutil.copy(video_path, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "        display(Markdown(f\"**{str(video_path)} selected for transcription.**\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "else:\n",
        "    raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    if video_path_local.suffix == \".mp4\":\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "        result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n"
      ],
      "metadata": {
        "id": "xYLPZQX9S7tU",
        "cellView": "form",
        "outputId": "6682e420-f43e-4bb2-a0d7-8b5e47b81b5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/bwWmI3krjEo\n",
            "[youtube] bwWmI3krjEo: Downloading webpage\n",
            "[youtube] bwWmI3krjEo: Downloading android player API JSON\n",
            "[youtube] bwWmI3krjEo: Downloading player c353919c\n",
            "[info] bwWmI3krjEo: Downloading 1 format(s): 140\n",
            "[dashsegments] Total fragments: 2\n",
            "[download] Destination: bwWmI3krjEo.m4a\n",
            "[download] 100% of   13.08MiB in 00:00:00 at 37.19MiB/s              \n",
            "[FixupM4a] Correcting container of \"bwWmI3krjEo.m4a\"\n",
            "[ExtractAudio] Destination: bwWmI3krjEo.wav\n",
            "Deleting original file bwWmI3krjEo.m4a (pass -k to keep)\n",
            "[youtube] Extracting URL: https://youtu.be/bwWmI3krjEo\n",
            "[youtube] bwWmI3krjEo: Downloading webpage\n",
            "[youtube] bwWmI3krjEo: Downloading android player API JSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-X0qB9JAzMLY",
        "cellView": "form",
        "collapsed": true,
        "outputId": "505f1bb6-9b58-461e-dc8c-8f8a3ab1f098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### bwWmI3krjEo.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:05.600] 中醫是難以學習的一種本領\n",
            "[00:06.600 --> 00:08.600] 我在這裡講過吧\n",
            "[00:09.320 --> 00:11.320] 我小時候還想自學成才呢\n",
            "[00:12.400 --> 00:14.400] 我一個老先生借了兩本書\n",
            "[00:14.400 --> 00:16.400] 他因為是業餘行經的\n",
            "[00:16.400 --> 00:18.400] 行得很有效\n",
            "[00:18.400 --> 00:20.400] 怎麼很有效\n",
            "[00:20.400 --> 00:24.200] 因為我父親多年的慢性窒息管炎的頑疾\n",
            "[00:24.200 --> 00:26.200] 結果他開了個方子\n",
            "[00:26.200 --> 00:29.600] 我幫我父親到中藥店裡去買那個藥\n",
            "[00:29.600 --> 00:31.600] 才一毛兩分\n",
            "[00:31.600 --> 00:33.600] 上海人一聽就知道了\n",
            "[00:33.600 --> 00:35.600] 一聽就要解決問題\n",
            "[00:35.600 --> 00:37.600] 當時還不相信\n",
            "[00:37.600 --> 00:39.600] 第二年到了季節交換的時候\n",
            "[00:39.600 --> 00:41.600] 我父親這病就不發了\n",
            "[00:41.600 --> 00:44.600] 這時候我對中醫肅然起敬\n",
            "[00:44.600 --> 00:46.600] 後來我就要向他學習\n",
            "[00:46.600 --> 00:48.600] 他借兩本書給我\n",
            "[00:48.600 --> 00:50.600] 第一本書叫中醫診斷學\n",
            "[00:50.600 --> 00:52.600] 南京中醫學院編的\n",
            "[00:52.600 --> 00:54.600] 第二本叫中藥學概論\n",
            "[00:54.600 --> 00:56.600] 北京醫學院編的\n",
            "[00:56.600 --> 00:58.600] 我想對他先診斷後開藥\n",
            "[00:59.600 --> 01:01.600] 這事情是很對的事情\n",
            "[01:01.600 --> 01:03.600] 所以先供一本中醫診斷學\n",
            "[01:03.600 --> 01:05.600] 那時候很輕鬆的\n",
            "[01:05.600 --> 01:07.600] 中學裡沒什麼課\n",
            "[01:07.600 --> 01:09.600] 下午都放假了\n",
            "[01:09.600 --> 01:11.600] 回家就去學中醫診斷學\n",
            "[01:11.600 --> 01:13.600] 寄了厚厚的筆記本\n",
            "[01:13.600 --> 01:15.600] 望聞問起四種手段\n",
            "[01:15.600 --> 01:17.600] 到了第四種的時候我嚇了一跳\n",
            "[01:17.600 --> 01:19.600] 這一章這個chapter\n",
            "[01:19.600 --> 01:21.600] 第一句話\n",
            "[01:21.600 --> 01:23.600] 脈象萬千\n",
            "[01:23.600 --> 01:25.600] 我想脈象萬千怎麼學\n",
            "[01:25.600 --> 01:27.600] 中醫講的脈象萬千\n",
            "[01:27.600 --> 01:29.600] 我們的脈象萬千\n",
            "[01:29.600 --> 01:31.600] 我嚇了一跳\n",
            "[01:31.600 --> 01:33.600] 第二句話給我鼓勵了\n",
            "[01:33.600 --> 01:35.600] 給我一點安慰\n",
            "[01:35.600 --> 01:37.600] 雖然脈象萬千大概有\n",
            "[01:37.600 --> 01:39.600] 錄下幾位我數二十幾位\n",
            "[01:39.600 --> 01:41.600] 還是有限的\n",
            "[01:41.600 --> 01:43.600] 一條一條學吧\n",
            "[01:43.600 --> 01:45.600] 第一個脈象叫洪脈\n",
            "[01:45.600 --> 01:47.600] 洪水的洪\n",
            "[01:47.600 --> 01:49.600] 這種脈象的感受他都用文字表達了一下\n",
            "[01:49.600 --> 01:51.600] 跳起來是有力量\n",
            "[01:51.600 --> 01:53.600] 所以叫洪水\n",
            "[01:53.600 --> 01:55.600] 寬廣有力\n",
            "[01:55.600 --> 01:57.600] 然後華脈\n",
            "[01:57.600 --> 01:59.600] 佛脈\n",
            "[01:59.600 --> 02:01.600] 慈脈宿脈玄脈\n",
            "[02:01.600 --> 02:03.600] 聖脈\n",
            "[02:03.600 --> 02:05.600] 我都現在背不清楚了\n",
            "[02:05.600 --> 02:07.600] 當時是每一條都寫好筆記的\n",
            "[02:07.600 --> 02:09.600] 全部反混搞清楚了\n",
            "[02:09.600 --> 02:11.600] 把不同的脈象在概念上區分開來\n",
            "[02:11.600 --> 02:13.600] 是吧\n",
            "[02:13.600 --> 02:15.600] 然後我請我姐姐把手伸出來\n",
            "[02:17.600 --> 02:19.600] 現在我來看看你什麼脈象\n",
            "[02:19.600 --> 02:21.600] 我呀\n",
            "[02:21.600 --> 02:23.600] 洪脈\n",
            "[02:23.600 --> 02:25.600] 跳得堅強有力\n",
            "[02:25.600 --> 02:27.600] 但是稍微多放點時間\n",
            "[02:27.600 --> 02:29.600] 發現有點華\n",
            "[02:29.600 --> 02:31.600] 還有點色\n",
            "[02:31.600 --> 02:33.600] 還有那麼點玄\n",
            "[02:33.600 --> 02:35.600] 終於不知道他什麼脈\n",
            "[02:39.600 --> 02:41.600] 然後我就去找那個老先生了\n",
            "[02:41.600 --> 02:43.600] 我說我已經一個多月下來\n",
            "[02:43.600 --> 02:45.600] 樹都看得滾瓜爛熟\n",
            "[02:45.600 --> 02:47.600] 把我老先生的脈象\n",
            "[02:47.600 --> 02:49.600] 看得滾瓜爛熟\n",
            "[02:49.600 --> 02:51.600] 把脈呢我也看清楚了\n",
            "[02:51.600 --> 02:53.600] 二十幾種是吧\n",
            "[02:53.600 --> 02:55.600] 但是我就不會把脈\n",
            "[02:55.600 --> 02:57.600] 他笑了我又沒叫你把脈\n",
            "[02:57.600 --> 02:59.600] 我先讓你看這本書是對中醫學\n",
            "[02:59.600 --> 03:01.600] 整個學說有一個概念\n",
            "[03:03.600 --> 03:05.600] 至於你要學會把脈\n",
            "[03:05.600 --> 03:07.600] 沒有別的辦法跟著我\n",
            "[03:07.600 --> 03:09.600] 我說跟你幹嘛\n",
            "[03:09.600 --> 03:11.600] 他說第一件事情領包\n",
            "[03:11.600 --> 03:13.600] 第二件事情我給病人看病的時候\n",
            "[03:13.600 --> 03:15.600] 寫下方式你幫我抄\n",
            "[03:15.600 --> 03:17.600] 第一領包\n",
            "[03:17.600 --> 03:19.600] 第二抄方式\n",
            "[03:19.600 --> 03:21.600] 我一聽就不大高興\n",
            "[03:21.600 --> 03:23.600] 他知道我已經不舒服了\n",
            "[03:23.600 --> 03:25.600] 他說了你準備怎麼樣\n",
            "[03:25.600 --> 03:27.600] 第一我先問你\n",
            "[03:27.600 --> 03:29.600] 我出去看病你跟著我\n",
            "[03:29.600 --> 03:31.600] 這個包是你領還是我領\n",
            "[03:33.600 --> 03:35.600] 對的師道尊嚴\n",
            "[03:35.600 --> 03:37.600] 肯定我領了你不要不高興\n",
            "[03:37.600 --> 03:39.600] 第二把脈這個事情\n",
            "[03:39.600 --> 03:41.600] 怎麼學的你知道嗎\n",
            "[03:41.600 --> 03:43.600] 就抄方式抄出來\n",
            "[03:43.600 --> 03:45.600] 他說這樣\n",
            "[03:45.600 --> 03:47.600] 我給病人把脈了\n",
            "[03:47.600 --> 03:49.600] 你也去把一把\n",
            "[03:49.600 --> 03:51.600] 把完了以後你心中在琢磨\n",
            "[03:51.600 --> 03:53.600] 是什麼脈象大概是什麼病\n",
            "[03:53.600 --> 03:55.600] 我也沒辦法跟你講這是什麼脈象\n",
            "[03:55.600 --> 03:57.600] 無法言傳\n",
            "[03:57.600 --> 03:59.600] 所以我就開了方式\n",
            "[03:59.600 --> 04:01.600] 開了方式你去抄\n",
            "[04:01.600 --> 04:03.600] 抄的時候你就在體會\n",
            "[04:03.600 --> 04:05.600] 我把出來的是什麼脈象才會開這種方式\n",
            "[04:05.600 --> 04:07.600] 然後你再去把一下\n",
            "[04:07.600 --> 04:09.600] 就這你第一次\n",
            "[04:09.600 --> 04:11.600] 把脈的感覺的生活\n",
            "[04:11.600 --> 04:13.600] 如此往復\n",
            "[04:13.600 --> 04:15.600] 我說要往復多久\n",
            "[04:15.600 --> 04:17.600] 十年\n",
            "[04:17.600 --> 04:19.600] 你幫我抄十年方式\n",
            "[04:19.600 --> 04:21.600] 就這件事情\n",
            "[04:21.600 --> 04:23.600] 我服了\n",
            "[04:23.600 --> 04:25.600] 但是後來我知道\n",
            "[04:25.600 --> 04:27.600] 也不肯老實跟著你\n",
            "[04:27.600 --> 04:29.600] 我還在讀書\n",
            "[04:29.600 --> 04:31.600] 他還是什麼\n",
            "[04:31.600 --> 04:33.600] 叫室內分子\n",
            "[04:33.600 --> 04:35.600] 我跟他打交道還避冷而莫\n",
            "[04:35.600 --> 04:37.600] 我還想參加\n",
            "[04:37.600 --> 04:39.600] 紅衛兵\n",
            "[04:39.600 --> 04:41.600] 跟壞分子在一起\n",
            "[04:41.600 --> 04:43.600] 不行的所以後來沒學成\n",
            "[04:43.600 --> 04:45.600] 後來我自己\n",
            "[04:45.600 --> 04:47.600] 讀哲學了又想起他跟我說的那番話\n",
            "[04:47.600 --> 04:49.600] 我真明白了\n",
            "[04:49.600 --> 04:51.600] 中醫是不可能在\n",
            "[04:51.600 --> 04:53.600] 中醫藥大學裡面批量生產出來的\n",
            "[04:53.600 --> 04:55.600] 這是不可能的\n",
            "[04:55.600 --> 04:57.600] 有一門課這個學期上\n",
            "[04:57.600 --> 04:59.600] 叫中醫診斷學\n",
            "[04:59.600 --> 05:01.600] 你很認真地坐在地下聽老師講歌\n",
            "[05:01.600 --> 05:03.600] 筆記記得清清楚楚的\n",
            "[05:03.600 --> 05:05.600] 就考試你得一百分你會把它賣嗎\n",
            "[05:05.600 --> 05:07.600] 不可能會\n",
            "[05:09.600 --> 05:11.600] 中醫的傳承\n",
            "[05:11.600 --> 05:13.600] 是師徒關係\n",
            "[05:13.600 --> 05:15.600] 沒有別的辦法\n",
            "[05:15.600 --> 05:17.600] 西醫的可以\n",
            "[05:17.600 --> 05:19.600] 批量生產的\n",
            "[05:19.600 --> 05:21.600] 診斷全是量化的\n",
            "[05:21.600 --> 05:23.600] 一個血液裡面\n",
            "[05:23.600 --> 05:25.600] 多種成分每一種成分\n",
            "[05:25.600 --> 05:27.600] 的正常者範圍\n",
            "[05:27.600 --> 05:29.600] 叫古兵轉安眉\n",
            "[05:29.600 --> 05:31.600] 正常者範圍\n",
            "[05:31.600 --> 05:33.600] 四捨超出四捨以上\n",
            "[05:33.600 --> 05:35.600] 肝臟有病據說他還能\n",
            "[05:35.600 --> 05:37.600] 播毒有時候放寬\n",
            "[05:37.600 --> 05:39.600] 放寬到六捨\n",
            "[05:39.600 --> 05:41.600] 反正他有個量化的你能學的\n",
            "[05:41.600 --> 05:43.600] 你就背嘛\n",
            "[05:43.600 --> 05:45.600] 學西醫難就難在人家記憶大量的東西\n",
            "[05:45.600 --> 05:47.600] 解剖血多少塊骨頭\n",
            "[05:47.600 --> 05:49.600] 它的位置他們的關係\n",
            "[05:49.600 --> 05:51.600] 背出來化驗\n",
            "[05:51.600 --> 05:53.600] 你轉每一門課\n",
            "[05:53.600 --> 05:55.600] 正常的血液和尿液的各種成分\n",
            "[05:55.600 --> 05:57.600] 的數字\n",
            "[05:57.600 --> 05:59.600] 全清楚背出來\n",
            "[05:59.600 --> 06:01.600] 所以西醫的診斷是可以\n",
            "[06:01.600 --> 06:03.600] 普遍習得的事情\n",
            "[06:03.600 --> 06:05.600] 中醫的診斷全是什麼\n",
            "[06:05.600 --> 06:07.600] 感覺感悟\n",
            "[06:07.600 --> 06:09.600] 所以沙家幫那個台詞\n",
            "[06:09.600 --> 06:11.600] 是對的\n",
            "[06:11.600 --> 06:13.600] 不用病家開口\n",
            "[06:13.600 --> 06:15.600] 辯治病情根源\n",
            "[06:15.600 --> 06:17.600] 說的對是我的藥說的不對奔奔不去\n",
            "[06:17.600 --> 06:19.600] 他不要你開口的\n",
            "[06:19.600 --> 06:21.600] 三隻手指\n",
            "[06:21.600 --> 06:23.600] 放在你的脈搏上代表了\n",
            "[06:23.600 --> 06:25.600] 全部檢測手段包括赫茲公正都在裡面\n",
            "[06:31.600 --> 06:33.600] 所以真正的中醫一定是生醫\n",
            "[06:35.600 --> 06:37.600] 生醫就是有偉大的哲學\n",
            "[06:39.600 --> 06:41.600] 而這個哲學是磨練出來的\n",
            "[06:41.600 --> 06:43.600] 要多少年\n",
            "[06:43.600 --> 06:45.600] 那個老先生說生也\n",
            "[06:47.600 --> 06:49.600] 其實還有一個基礎他沒說出來\n",
            "[06:49.600 --> 06:51.600] 你的悟性\n",
            "[06:51.600 --> 06:53.600] 你的感悟能力\n",
            "[06:53.600 --> 06:55.600] 你這時候一定要少學西方科學\n",
            "[06:55.600 --> 06:57.600] 因為西方科學學的一多\n",
            "[06:57.600 --> 06:59.600] 你的邏輯思考就來了\n",
            "[06:59.600 --> 07:01.600] 邏輯思考就妨礙你的哲學能力的發展\n",
            "[07:01.600 --> 07:03.600] 不能搞邏輯的東西\n",
            "[07:05.600 --> 07:07.600] 我後來就學過一些命理學\n",
            "[07:07.600 --> 07:09.600] 就算命\n",
            "[07:09.600 --> 07:11.600] 就八字\n",
            "[07:11.600 --> 07:13.600] 生成八字年月日時\n",
            "[07:13.600 --> 07:15.600] 用天干地支表達的\n",
            "[07:15.600 --> 07:17.600] 年有兩個字吧\n",
            "[07:17.600 --> 07:19.600] 年干年止\n",
            "[07:19.600 --> 07:21.600] 比如說今年是病生年\n",
            "[07:21.600 --> 07:23.600] 兩個字了吧\n",
            "[07:23.600 --> 07:25.600] 每個月也有月干月止\n",
            "[07:25.600 --> 07:27.600] 有兩個字四個字\n",
            "[07:27.600 --> 07:29.600] 每一天都有日干日止\n",
            "[07:29.600 --> 07:31.600] 每一個時辰\n",
            "[07:31.600 --> 07:33.600] 時干時止一共八個字\n",
            "[07:33.600 --> 07:35.600] 你在這個時間裏面出生出來\n",
            "[07:35.600 --> 07:37.600] 上天給了你開了一個藥方\n",
            "[07:37.600 --> 07:39.600] 就是你的八字\n",
            "[07:39.600 --> 07:41.600] 什麼叫看命\n",
            "[07:41.600 --> 07:43.600] 跟看藥方完全一樣\n",
            "[07:45.600 --> 07:47.600] 藥性\n",
            "[07:47.600 --> 07:49.600] 判斷你的命運和性格\n",
            "[07:49.600 --> 07:51.600] 就是看你這個上天給你開的\n",
            "[07:51.600 --> 07:53.600] 藥方的藥性\n",
            "[07:53.600 --> 07:55.600] 天干地支就是金莫水火土\n",
            "[07:59.600 --> 08:01.600] 比如說今年出生的人\n",
            "[08:01.600 --> 08:03.600] 猴年以後的猴子\n",
            "[08:03.600 --> 08:05.600] 他的八字裏面一定有兩個成分金\n",
            "[08:05.600 --> 08:07.600] 你可以斷言了\n",
            "[08:07.600 --> 08:09.600] 一他有火的病輸火\n",
            "[08:09.600 --> 08:11.600] 二他有金\n",
            "[08:11.600 --> 08:13.600] 生輸金\n",
            "[08:13.600 --> 08:15.600] 你已經知道了\n",
            "[08:15.600 --> 08:17.600] 你說這個人今年出生的\n",
            "[08:17.600 --> 08:19.600] 他裏面去吃火吃金\n",
            "[08:19.600 --> 08:21.600] 這不可能的\n",
            "[08:21.600 --> 08:23.600] 這已經定好了你知道\n",
            "[08:23.600 --> 08:25.600] 然後你具體了解哪一月出生的\n",
            "[08:25.600 --> 08:27.600] 哪一日出生的\n",
            "[08:27.600 --> 08:29.600] 八個字全了\n",
            "[08:29.600 --> 08:31.600] 全了金莫水火土你看\n",
            "[08:31.600 --> 08:33.600] 他有藥性的\n",
            "[08:33.600 --> 08:35.600] 看八字就是看藥性\n",
            "[08:35.600 --> 08:37.600] 從藥性裏面推出\n",
            "[08:37.600 --> 08:39.600] 他的特徵和他的命運的道路\n",
            "[08:39.600 --> 08:41.600] 跟中醫完全是同的\n",
            "[08:41.600 --> 08:43.600] 所以中國古代的\n",
            "[08:43.600 --> 08:45.600] 中醫真正的中醫同時\n",
            "[08:45.600 --> 08:47.600] 一定會看八字\n",
            "[08:47.600 --> 08:49.600] 不可能不會看到\n",
            "[08:49.600 --> 08:51.600] 所以你中醫學到好\n",
            "[08:51.600 --> 08:53.600] 學八字算命\n",
            "[08:53.600 --> 08:55.600] 很快全通的\n",
            "[08:55.600 --> 08:57.600] 而且中醫以前的概念\n",
            "[08:57.600 --> 08:59.600] 就是有一句話\n",
            "[08:59.600 --> 09:01.600] 治得了病治不了命\n",
            "[09:01.600 --> 09:03.600] 所以他\n",
            "[09:03.600 --> 09:05.600] 講究一點的如果\n",
            "[09:05.600 --> 09:07.600] 某人的病某一個患者的病比較嚴重\n",
            "[09:07.600 --> 09:09.600] 他會怎麼了解一下他出生的時間\n",
            "[09:09.600 --> 09:11.600] 然後他八字\n",
            "[09:11.600 --> 09:13.600] 自己撕下來一排看看還能救\n",
            "[09:17.600 --> 09:19.600] 不能就算了跟你說一句話\n",
            "[09:19.600 --> 09:21.600] 治不了命的\n",
            "[09:21.600 --> 09:23.600] 治得了病\n",
            "[09:23.600 --> 09:25.600] 全是有道理的\n",
            "[09:27.600 --> 09:29.600] 所以這個學問全通的\n",
            "[09:29.600 --> 09:31.600] 全是通的\n",
            "[09:31.600 --> 09:33.600] 所以這個中國的\n",
            "[09:33.600 --> 09:35.600] 陰陽五行學說的宇宙觀\n",
            "[09:35.600 --> 09:37.600] 帶來中國各種科學\n",
            "[09:39.600 --> 09:41.600] 同時又能夠談人事\n",
            "[09:49.600 --> 09:51.600] 所以中醫的學習就是這樣\n",
            "[09:51.600 --> 09:53.600] 就像中國所有的學問都是\n",
            "[09:53.600 --> 09:55.600] 師徒相傳\n",
            "[09:55.600 --> 09:57.600] 他無法批量生產\n",
            "[09:57.600 --> 09:59.600] 他是建立在非設計性的感覺\n",
            "[09:59.600 --> 10:01.600] 的基礎上什麼叫哲學\n",
            "[10:01.600 --> 10:03.600] 非設計性感覺\n",
            "[10:03.600 --> 10:05.600] 給大家讓希望人能理解\n",
            "[10:05.600 --> 10:07.600] 非設計性感覺\n",
            "[10:07.600 --> 10:09.600] 這種感覺有靈性\n",
            "[10:09.600 --> 10:11.600] 在這種靈性哲學上面\n",
            "[10:11.600 --> 10:13.600] 可以辯論\n",
            "[10:13.600 --> 10:15.600] 我舉個簡單的例子\n",
            "[10:15.600 --> 10:17.600] 看過一部電影叫未來世界\n",
            "[10:17.600 --> 10:19.600] 老子一千方法就科幻的\n",
            "[10:19.600 --> 10:21.600] 就某一個狂人\n",
            "[10:21.600 --> 10:23.600] 他搞了一個旅遊勝地\n",
            "[10:23.600 --> 10:25.600] 吸引許多人去玩\n",
            "[10:25.600 --> 10:27.600] 他最好吸引世界名人去\n",
            "[10:27.600 --> 10:29.600] 各國的總統去\n",
            "[10:29.600 --> 10:31.600] 為什麼一進去就被他綁架\n",
            "[10:31.600 --> 10:33.600] 綁架了以後在他人體上\n",
            "[10:33.600 --> 10:35.600] 取得所有的信息\n",
            "[10:35.600 --> 10:37.600] 然後把他殺了\n",
            "[10:37.600 --> 10:39.600] 造個什麼機器人\n",
            "[10:39.600 --> 10:41.600] 他的膚色面容跟原來的完全一樣\n",
            "[10:41.600 --> 10:43.600] 然後他照樣走出來\n",
            "[10:43.600 --> 10:45.600] 你不知道了\n",
            "[10:45.600 --> 10:47.600] 這個人是普京\n",
            "[10:47.600 --> 10:49.600] 歐巴馬\n",
            "[10:49.600 --> 10:51.600] 歐巴馬已經真的殺掉了\n",
            "[10:51.600 --> 10:53.600] 他現在是個機器人在你面前\n",
            "[10:53.600 --> 10:55.600] 而且他全知道\n",
            "[10:55.600 --> 10:57.600] 信息全有\n",
            "[10:57.600 --> 10:59.600] 童年少年所有的精靈\n",
            "[10:59.600 --> 11:01.600] 信息都佈置好了\n",
            "[11:01.600 --> 11:03.600] 佈置好了以後這個狂人\n",
            "[11:03.600 --> 11:05.600] 這個旅遊勝地的主人\n",
            "[11:05.600 --> 11:07.600] 他通過把世界各國的首腦元首\n",
            "[11:07.600 --> 11:09.600] 都換成他那個智慧的人\n",
            "[11:09.600 --> 11:11.600] 他統治世界\n",
            "[11:11.600 --> 11:13.600] 有這個意思\n",
            "[11:13.600 --> 11:15.600] 有一對戀人同時是心動記者\n",
            "[11:15.600 --> 11:17.600] 闖入了這個勝地\n",
            "[11:17.600 --> 11:19.600] 勝地以後他們很快被抓起來了\n",
            "[11:19.600 --> 11:21.600] 抓起來以後\n",
            "[11:21.600 --> 11:23.600] 結果憑他們的機智勇敢\n",
            "[11:23.600 --> 11:25.600] 擺脫了沒弄成\n",
            "[11:25.600 --> 11:27.600] 然後他們逃到了勝地的出口處\n",
            "[11:27.600 --> 11:29.600] 兩個人相遇了\n",
            "[11:29.600 --> 11:31.600] 男的看到女的\n",
            "[11:31.600 --> 11:33.600] 女的也看到男的\n",
            "[11:33.600 --> 11:35.600] 就心裡在想你是真的嗎\n",
            "[11:35.600 --> 11:37.600] 這是個嚴重的事情\n",
            "[11:37.600 --> 11:39.600] 我不知道是真的還是假的\n",
            "[11:39.600 --> 11:41.600] 後來他們怎麼解決這個問題\n",
            "[11:41.600 --> 11:43.600] 因為他們是戀人\n",
            "[11:43.600 --> 11:45.600] 他們是情侶\n",
            "[11:45.600 --> 11:47.600] 在親吻的一刻\n",
            "[11:47.600 --> 11:49.600] 彼此都知道對方是真的\n",
            "[11:51.600 --> 11:53.600] 因為這種吻啊\n",
            "[11:53.600 --> 11:55.600] 只有他們自己明白\n",
            "[11:55.600 --> 11:57.600] 這叫什麼\n",
            "[11:57.600 --> 11:59.600] 非捨棄性感\n",
            "[12:03.600 --> 12:05.600] 中國學問就建立在\n",
            "[12:05.600 --> 12:07.600] 這種非捨棄性感的基礎上\n",
            "[12:07.600 --> 12:09.600] 才能實踐的\n",
            "[12:09.600 --> 12:11.600] 這種學問\n",
            "[12:11.600 --> 12:13.600] 我看八字學命理學\n",
            "[12:13.600 --> 12:15.600] 我勸許多人不要學\n",
            "[12:15.600 --> 12:17.600] 我在裡面長進了七進了幹口\n",
            "[12:17.600 --> 12:19.600] 為什麼我是學西方自然科學長大的\n",
            "[12:19.600 --> 12:21.600] 然後呢把八字算命的命理學\n",
            "[12:21.600 --> 12:23.600] 一本又一本看\n",
            "[12:23.600 --> 12:25.600] 全是邏輯勢力上的循環\n",
            "[12:25.600 --> 12:27.600] 結果八字看不懂\n",
            "[12:27.600 --> 12:29.600] 到後來我終於\n",
            "[12:29.600 --> 12:31.600] 盡力擺脫邏輯思考\n",
            "[12:31.600 --> 12:33.600] 現在差不多做到什麼\n",
            "[12:33.600 --> 12:35.600] 你一個八字給我看的時候我一看\n",
            "[12:35.600 --> 12:37.600] 又感受來了\n",
            "[12:37.600 --> 12:39.600] 硬的還是軟的\n",
            "[12:39.600 --> 12:41.600] 這個工的\n",
            "[12:41.600 --> 12:43.600] 屬次的還是貫通的\n",
            "[12:43.600 --> 12:45.600] 乾燥的還是潮濕的\n",
            "[12:45.600 --> 12:47.600] 這種感覺全來了\n",
            "[12:47.600 --> 12:49.600] 你才這樣看呢\n",
            "[12:49.600 --> 12:51.600] 就看要心\n",
            "[12:51.600 --> 12:53.600] 所以命理學的實踐\n",
            "[12:53.600 --> 12:55.600] 一直主張兩個字叫活看\n",
            "[12:55.600 --> 12:57.600] 你別把命理學的\n",
            "[12:57.600 --> 12:59.600] 一條條的說法當成教條\n",
            "[12:59.600 --> 13:01.600] 背出來就能看不會看\n",
            "[13:01.600 --> 13:03.600] 要活看\n",
            "[13:03.600 --> 13:05.600] 就整體的看\n",
            "[13:05.600 --> 13:07.600] 就像朱醫給你看人體的肌肉一樣\n",
            "[13:07.600 --> 13:09.600] 它是完整的一個整體\n",
            "[13:09.600 --> 13:11.600] 它們之間的相互關係\n",
            "[13:11.600 --> 13:13.600] 要靠這種\n",
            "[13:13.600 --> 13:15.600] 灰色體系的感受\n",
            "[13:15.600 --> 13:19.600] 中國科學難以\n",
            "[13:19.600 --> 13:21.600] 傳承的原因\n",
            "[13:21.600 --> 13:23.600] 就是這個原因\n",
            "[13:23.600 --> 13:25.600] 當然它需要名譽\n",
            "[13:25.600 --> 13:27.600] 許多一家世代的\n",
            "[13:27.600 --> 13:29.600] 醫生他有道理\n",
            "[13:29.600 --> 13:31.600] 因為他傳給兒子兒子傳給孫子\n",
            "[13:31.600 --> 13:33.600] 朝夕相處\n",
            "[13:33.600 --> 13:35.600] 而如莫然\n",
            "[13:35.600 --> 13:37.600] 就這樣認出來\n",
            "[13:37.600 --> 13:39.600] 所以中醫還有拯救的希望嗎\n",
            "[13:39.600 --> 13:41.600] 取決於兩方面\n",
            "[13:41.600 --> 13:43.600] 第一我們改變中醫學的教學制度\n",
            "[13:43.600 --> 13:45.600] 不要拿西方教育制度來\n",
            "[13:45.600 --> 13:47.600] 我們要恢復私塾\n",
            "[13:47.600 --> 13:49.600] 這種形式要在中醫\n",
            "[13:49.600 --> 13:51.600] 傳承到私塾相承的關係\n",
            "[13:51.600 --> 13:53.600] 這是第一\n",
            "[13:53.600 --> 13:55.600] 第二中藥的生產\n",
            "[13:55.600 --> 13:57.600] 種植\n",
            "[13:57.600 --> 13:59.600] 一定要嚴格\n",
            "[13:59.600 --> 14:01.600] 這樣否則的話\n",
            "[14:01.600 --> 14:03.600] 你藥開出來\n",
            "[14:03.600 --> 14:05.600] 就沒這麼大的效果\n",
            "[14:05.600 --> 14:07.600] 這兩條是基本的\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/My Drive/Colab Notebooks/Whisper Youtube/bwWmI3krjEo.txt**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/My Drive/Colab Notebooks/Whisper Youtube/bwWmI3krjEo.vtt**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/My Drive/Colab Notebooks/Whisper Youtube/bwWmI3krjEo.srt**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/My Drive/Colab Notebooks/Whisper Youtube/bwWmI3krjEo.tsv**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/My Drive/Colab Notebooks/Whisper Youtube/bwWmI3krjEo.json**"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # **Run the model** 🚀\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** ⚙️\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"Chinese\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "output_format = 'all' #@param ['txt', 'vtt', 'srt', 'tsv', 'json', 'all']\n",
        "#@markdown > Type of file to generate to record the transcription.\n",
        "#@markdown ---\n",
        "task = 'transcribe' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <br/>\n",
        "\n",
        "#@markdown ### **Optional: Fine tunning** \n",
        "#@markdown ---\n",
        "temperature = 0.15 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to use for sampling.\n",
        "#@markdown ---\n",
        "temperature_increment_on_fallback = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to increase when falling back when the decoding fails to meet either of the thresholds below.\n",
        "#@markdown ---\n",
        "best_of = 5 #@param {type:\"integer\"}\n",
        "#@markdown > Number of candidates when sampling with non-zero temperature.\n",
        "#@markdown ---\n",
        "beam_size = 8 #@param {type:\"integer\"}\n",
        "#@markdown > Number of beams in beam search, only applicable when temperature is zero.\n",
        "#@markdown ---\n",
        "patience = 1.0 #@param {type:\"number\"}\n",
        "#@markdown > Optional patience value to use in beam decoding, as in [*Beam Decoding with Controlled Patience*](https://arxiv.org/abs/2204.05424), the default (1.0) is equivalent to conventional beam search.\n",
        "#@markdown ---\n",
        "length_penalty = -0.05 #@param {type:\"slider\", min:-0.05, max:1, step:0.05}\n",
        "#@markdown > Optional token length penalty coefficient (alpha) as in [*Google's Neural Machine Translation System*](https://arxiv.org/abs/1609.08144), set to negative value to uses simple length normalization.\n",
        "#@markdown ---\n",
        "suppress_tokens = \"-1\" #@param {type:\"string\"}\n",
        "#@markdown > Comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations.\n",
        "#@markdown ---\n",
        "initial_prompt = \"\" #@param {type:\"string\"}\n",
        "#@markdown > Optional text to provide as a prompt for the first window.\n",
        "#@markdown ---\n",
        "condition_on_previous_text = True #@param {type:\"boolean\"}\n",
        "#@markdown > if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop.\n",
        "#@markdown ---\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "#@markdown > whether to perform inference in fp16.\n",
        "#@markdown ---\n",
        "compression_ratio_threshold = 2.4 #@param {type:\"number\"}\n",
        "#@markdown > If the gzip compression ratio is higher than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "logprob_threshold = -1.0 #@param {type:\"number\"}\n",
        "#@markdown > If the average log probability is lower than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "no_speech_threshold = 0.6 #@param {type:\"slider\", min:-0.0, max:1, step:0.05}\n",
        "#@markdown > If the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "args = dict(\n",
        "    language = (None if language == \"Auto detection\" else language),\n",
        "    verbose = verbose_lut[verbose],\n",
        "    task = task,\n",
        "    temperature = temperature,\n",
        "    temperature_increment_on_fallback = temperature_increment_on_fallback,\n",
        "    best_of = best_of,\n",
        "    beam_size = beam_size,\n",
        "    patience=patience,\n",
        "    length_penalty=(length_penalty if length_penalty>=0.0 else None),\n",
        "    suppress_tokens=suppress_tokens,\n",
        "    initial_prompt=(None if not initial_prompt else initial_prompt),\n",
        "    condition_on_previous_text=condition_on_previous_text,\n",
        "    fp16=fp16,\n",
        "    compression_ratio_threshold=compression_ratio_threshold,\n",
        "    logprob_threshold=logprob_threshold,\n",
        "    no_speech_threshold=no_speech_threshold\n",
        ")\n",
        "\n",
        "temperature = args.pop(\"temperature\")\n",
        "temperature_increment_on_fallback = args.pop(\"temperature_increment_on_fallback\")\n",
        "if temperature_increment_on_fallback is not None:\n",
        "    temperature = tuple(np.arange(temperature, 1.0 + 1e-6, temperature_increment_on_fallback))\n",
        "else:\n",
        "    temperature = [temperature]\n",
        "\n",
        "if Model.endswith(\".en\") and args[\"language\"] not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{args['language']}'; using English instead.\")\n",
        "    args[\"language\"] = \"en\"\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    display(Markdown(f\"### {video_path_local}\"))\n",
        "\n",
        "    video_transcription = whisper.transcribe(\n",
        "        whisper_model,\n",
        "        str(video_path_local),\n",
        "        temperature=temperature,\n",
        "        **args,\n",
        "    )\n",
        "\n",
        "    # Save output\n",
        "    whisper.utils.get_writer(\n",
        "        output_format=output_format,\n",
        "        output_dir=video_path_local.parent\n",
        "    )(\n",
        "        video_transcription,\n",
        "        str(video_path_local.stem),\n",
        "        options=dict(\n",
        "            highlight_words=False,\n",
        "            max_line_count=None,\n",
        "            max_line_width=None,\n",
        "        )\n",
        "    )\n",
        "    try:\n",
        "        if output_format==\"all\":\n",
        "            for ext in ('txt', 'vtt', 'srt', 'tsv', 'json'):\n",
        "                transcript_file_name = video_path_local.stem + \".\" + ext\n",
        "                shutil.copy(\n",
        "                    video_path_local.parent / transcript_file_name,\n",
        "                    drive_whisper_path / transcript_file_name\n",
        "                )\n",
        "                display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "        else:\n",
        "            transcript_file_name = video_path_local.stem + \".\" + output_format\n",
        "            shutil.copy(\n",
        "                video_path_local.parent / transcript_file_name,\n",
        "                drive_whisper_path / transcript_file_name\n",
        "            )\n",
        "            display(Markdown(f\"**Transcript file created: {drive_whisper_path / transcript_file_name}**\"))\n",
        "\n",
        "    except:\n",
        "        display(Markdown(f\"**Transcript file created: {transcript_local_path}**\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ad6n1m4deAHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}